{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios Sesión 4\n",
    "\n",
    "Acá estudiaremos la data pandémica del Minsal para construir un informe que analice la pandemia en Chile. Claramente, no redactamos el Word, sino que nos dedicaremos a calcular lo necesario usando Python.\n",
    "\n",
    "<p>\n",
    "<font size='1'>Material creado por &copy; 2024 José Tomás Marquinez, todos los derechos reservados. Data disponible originalmente en el <a href=\"https://github.com/MinCiencia\">Github del Ministerio de Ciencias de Chile</a> (lo sacaron), pero ahora extraída desde <a href=\"https://www.kaggle.com/datasets/dataobservatory/datoscovid19chile\">Kaggle</a> (Productos 6, 9, y 91)</font>\n",
    "<br>\n",
    "\n",
    "**Sugerencia de trabajo:** Comenzar desde la pantalla de un integrante, ELIMINAR OUTPUTS, registrar cambios, y luego dividirse las primeras preguntas. Cuando terminen, hacer `git pull` para discutir lo realizado y los resultados obtenidos. Si queda tiempo, continuar con la segunda mitad de preguntas, pero sin coordinar qué preguntas responderá cada uno, para trabajar nuevamente con conflictos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis Pandémico - COVID-19 en Chile\n",
    "\n",
    "En la carpeta `data` les dejé tres archivos que les puede interesar. A continuación se los detallo:\n",
    "\n",
    "- `data_covid_confirmados_cl.xlsx` (Adaptado del Producto 6): Da cuenta de los casos confirmados **acumulados** en cada una de las comunas de Chile, según residencia, conforme a los informes epidemiológicos publicados por el Ministerio de Salud del país. Contiene las columnas:\n",
    "    - `Fecha`\n",
    "    - `Region`: Nombre de la región\n",
    "    - `Region ID`: Número de la región\n",
    "    - `Comuna`: Nombre de la comuna\n",
    "    - `Comuna ID`: Número de la comuna\n",
    "    - `Casos Confirmados`: casos confirmados **acumulados** a la fecha,\n",
    "    - `Poblacion`: cantidad de habitantes de la comuna, \n",
    "\n",
    "- `data_covid_en_uci_por_rango_etario_cl.csv` (Producto 9): Da cuenta del número de pacientes **actualmente** en UCI por grupos etarios (<=39; 40-49; 50-59; 60-69; y >=70) y que son casos confirmados por COVID-19, reportados diariamente por el Ministerio de Salud, desde el 01-04-2020. El archivo contiene la columna:\n",
    "    - `Grupo de edad`: Rango etario\n",
    "    - Columnas `[Fecha]`: Estas últimas columnas indican el número de pacientes ocupando cama UCI por grupo etario, desde el 01-04-2020 hasta la fecha.\n",
    "\n",
    "- `data_covid_ingresos_mm_uci_cl.csv`: (Producto 91): Media móvil de los últimos 7 días de **ingresos** a UCI por covid en el sistema integrado de salud, público-privado.\n",
    "    - `Serie`: Nombre de la serie\n",
    "    - Columnas `[Fecha]`: Estas últimas columnas indican la media móvil de 7 días del número de ingresos a UCI. Por ejemplo, que el 16 de abril del 2020 indique 27.71 pacientes, significa que en promedio ingresaron 27.71 pacientes diarios a nivel nacional en la semana que termina en el 16 de abril."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirmados en el tiempo\n",
    "\n",
    "Primero, trabajemos con el archivo sobre confirmados. Note que es un archivo Excel. Léalo y cárguelo en su _notebook_ en un _DataFrame_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analice un poco el contenido del archivo. Por ejemplo, vea cuántas filas y columnas tiene, y muestre las primeras 10 filas. Además, vea los tipos de datos de las columnas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notará que la columna `Fecha` se leyó como _str_ (`object`). Convirtámoslo a fecha. Para ello, una _Serie_ (una columna) puede ser convertida a fecha utilizando la función `to_datetime()` de `Pandas`, que recibe como parámetro la columna a ser convertida, y la retorna convertida (por ende, podemos asignársela a la misma columna de vuelta)\n",
    "\n",
    "```Python\n",
    "df['col'] = pd.to_datetime(df['col'])\n",
    "```\n",
    "Incluso se le puede ayudar un poco con el formato en caso de ser necesario:\n",
    "\n",
    "```Python\n",
    "df['col'] = pd.to_datetime(df['col'], format=\"%Y/%m/%d\")    # o \"%m-%d%-%Y\"\n",
    "```\n",
    "\n",
    "Hágalo con la columna `Fecha` y luego verifique que quedó con el tipo de dato correcto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscamos analizar su comuna de residencia. Para ello, primero veamos cuántas regiones existen en Chile, y quizás (sólo quizás) nos demos cuenta que la forma de escribir estas comunas pueden variar a su notación común (nombre más corto, escrito distinto, etc). Por lo mismo (y para ilustrar esto más aún), enliste a continuación cuáles son todos los valores únicos existentes bajo la columna **`Region`** para ver cómo están escritos los nombres de las regiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible notar que la Región del Libertador Bernardo O'Higgins en la base aparece sólamente como O'Higgins, además de que el nombre lo tiene escrito con un caracter apóstrofe distinto a `\"'\"`. Eso no era trivial de reconocer sin antes explorar.\n",
    "\n",
    "Copie el texto asociado a su región de residencia, y filtre el dataset para su región en particular. No sobreescriba el dataframe original, pues lo usaremos más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, para esa región, enliste todas las comunas para ver cómo se encuentra escrita su comuna de residencia en la base (por ejemplo, no podemos saber a priori si La Higuera se encuentra escrita como \"Higuera\" o como \"La Higuera\"; lo mismo con \"Olmue\" vs \"Olmué\", o \"O'Higgins\" vs \"OHiggins\"), y luego cree un _dataframe_ sólo con la información asociada a su comuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ver los valores de las comunas, descubrimos un \"Desconocido Región\". Eso es porque hay confirmados que vinieron sin residencia clara o especificada.\n",
    "\n",
    "Ahí, ya es posible observar, por ejemplo, que todas las columnas salvo la de casos confirmados y la de la fecha tienen los mismos valores para todas las filas dada una única comuna. También podemos notar que la columna `Fecha` no necesariamente está ordenada. Ordene el dataframe de la comuna para que quede ordenado temporalmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entendiendo que la columna `Casos Confirmados` indica la cantidad de casos acumulados en el tiempo para cada fecha, determine la cantidad final de confirmados (según esta base de datos) para la comuna. Notemos que como el valor siempre crece, basta con calcularle el máximo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cree un DataFrame de sólo una columna con los nombres de todas las regiones. (`pd.DataFrame(resultado)`, en donde `resultado` puede ser el describir cuáles son los nombres únicos asociados a una columna). Sugiero cambiarle el nombre a la columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ese DataFrame, créele una columna adicional que calcule la cantidad de caracteres que tiene cada uno de esos nombres. (Sí, no es algo que sea muy necesario calcular, pero ayuda a ejercitar el `apply` y las funciones `lambda`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvamos al _DataFrame_ original. ¿Podemos analizar cuántas comunas hay por región? Puedes usar la función agregadora `nunique()` que indica cuántos valores únicos hay por grupo. Luego, ordena el resultado de mayor cantidad de comunas a menor cantidad de comunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nivel nacional, vea cuál es la comuna que terminó con la mayor cantidad de confirmados acumulados.\n",
    "\n",
    "_Hint:_ Para filtrar las filas con fecha igual a un valor en particular, se puede generar un valor de fecha como `pd.to_datetime('2024-04-05')`, o bien también se puede calcular la fecha máxima.\n",
    "\n",
    "¿Se la juegan con el mínimo (sin que sea una comuna con valor \"Desconocido\")?\n",
    "\n",
    "_Hint 2:_ Para filtrar aquellas comunas vacías, recuerde el `.notnull()`, y note el valor de `Comuna ID` para las comunas \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(\"2023-01-09\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aprovechando que ya enlistamos los nombres de las regiones más arriba, calculemos el total de confirmados acumulado final entre las 3 regiones con mayor _cantidad de **comunas**_, y compárela con la cantidad total de confirmados acumulados final entre el resto de las regiones. Para esto, considere que el método `isin()` puede recibir como parámetro una lista de valores (por ejemplo, una lista de _str_ de interés). Por ejemplo:\n",
    "\n",
    "```Python\n",
    "df[df['col'].isin([\"a\",\"b\",\"c\"])]\n",
    "```\n",
    "\n",
    "Esto retornará el dataframe resultante con todas las filas que, bajo la columna `col` tienen los valores `a`, `b`, o `c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a agregar un poco la información. Para ello, consideremos sólo la última fecha. Cree un _DataFrame_ que considere sólo la última fecha. Deberían quedarles 362 filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Pero no eran 345 comunas las que tenía Chile? Contemos cuántas veces aparece cada comuna en la columna `Comuna` (`.value_counts()`) del dataframe resultante, pero asegúrese de no esconder los `nan` (`.value_counts(dropna=False)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahí estaba el problema (ver la última fila). No podemos eliminar esos valores porque sí hay confirmados a esa fecha que no tienen comuna identificada. ¿Cuántos confirmados totales entre todas las comunas hubo al término de esta base?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuántos confirmados terminaron en la _comuna_ de `Santiago`? ¿Y en la comuna de `Panguipulli`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿A cuál de las dos comunas pareciera que le fue \"mejor\"? La respuesta pareciera ser directa. Santiago tuvo casi 10 veces más confirmados que Panguipulli, pero fíjese también en sus poblaciones. Santiago es importantemente más grande en población que Panguipulli. En el mundo epidémico existe un valor que se conoce como _Tasa de incidencia_, que estandariza estos valores a la población local de cada región/comuna. La fórmula es la siguiente:\n",
    "\n",
    "$ Tasa = \\frac{Casos}{Población} \\cdot 100.000 $\n",
    "\n",
    "(También se puede calcular por 10.000; ahí depende de la gravedad de la pandemia). Si una tasa da 150, quiere decir que 150 de cada 100.000 personas (independiente de la población real de la comuna/región) se contagió. Calculemos la tasa para todas las comunas, creando una columna sobre el dataframe que tenemos sobre la última fecha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Puede que les haya aparecido un Warning... honestamente omítanlo) \n",
    "\n",
    "¿Cambió su respuesta sobre cuál entre esas dos comunas \"le fue peor\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora todo este último análisis es sobre la última fecha registrada en la base. Vamos ahora a calcular la cantidad de confirmados diarios (serie de tiempo) a nivel nacional. Para eso, comencemos encontrando la cantidad de confirmados acumulados de forma diaria, es decir, necesitaremos agrupar totales a nivel `Fecha`. Luego de hacerlo, resetee los índices (`.reset_index()`) para convertirlo a _DataFrame_ y almacene el resultado en un nuevo _DataFrame_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A este nuevo _DataFrame_ agreguémosle una tercera columna indicando la cantidad de confirmados **nuevos** por día. Para ello, es posible usar el método `.diff()` sobre una _Serie_.\n",
    "\n",
    "```Python\n",
    "df['diferencia_entre_filas'] = df['valor_acumulado'].diff()\n",
    "df['diferencia_entre_filas'] = df['diferencia_entre_filas'].fillna(0) # Como la primera fila quedará vacía, rellenamos las celdas vacías con 0s (o con el valor que queramos). \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafiquemos la curva pandémica. Grafique los casos nuevos diarios a nivel nacional. Puede que tenga que configurar los valores de parámetros para especificar qué valor quiere que sea su eje `x`, y qué valor quiere que se su eje `y`.\n",
    "\n",
    "```Python\n",
    "df.plot(x='col1',y='col2')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uffff, no se ve como lo que mostraban en la tele. Esto se debe a que en el registro de datos existe una temporalidad periódica natural (los sábados y domingos se registran menos valores que los días de semana). Por eso, es que lo que hacen es suavizar la curva (o, en palabras técnicas, calcular la media móvil de 7 días). Para ello, necesitamos tener información sobre todos los días (y que no hayan días ausentes). Para esto los ayudo un poco. Crearemos un DataFrame con todos los días desde el 2020-03-30 hasta el 2023-01-09."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genero el rango de fechas\n",
    "rango_fechas = pd.date_range(start='2020-03-30', end='2023-01-09', freq='D')\n",
    "# Creo el DataFrame a partir del rango de fechas\n",
    "df_fechas = pd.DataFrame(rango_fechas, columns=['Fecha'])\n",
    "df_fechas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos _unir_ nuestro _DataFrame_ a este, en busca de rellenar este _DataFrame_ con las columnas presentes en el que estábamos trabajando. (_Hint:_ `merge` puede ser de utilidad, rellenando las fechas actualmente vacías con valores 0 para los casos nuevos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque esas celdas vacías del dataset igual nos van a perjudicar, démosle con el cálculo de la media móvil.\n",
    "\n",
    "Para ello, es posible usar el método `rolling()`, que puede recibir el parámetro `window` que indica el largo de la ventana móvil; mientras que el agregador `mean()` indica que estamos calculando la media para esa ventana\n",
    "```Python\n",
    "df['media_movil_7d'] = df['col'].rolling(window=7).mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafiquemos ahora sí la media móvil:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Ahí se parece más!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UCI en el tiempo\n",
    "\n",
    "Vamos con el segundo archivo sobre la media móvil de ingresos a UCI. Cárguelo y vea cómo son sus filas y dimensiones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es el formato real en el que se descargó el archivo, sin simplificaciones mías. Lo primero a notar es que tenemos el archivo más horizontal que vertical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si lo que queremos es trasponer esto, se puede hacer fácilmente con el método `.transpose()` sobre el mismo _DataFrame_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ve cómo quedó el resultado de esa trasposición, son requeridos un par de arreglos: resetear los índices para que se enumeren correctamente, darle nombre adecuado a los encabezados de columna, eliminar la primera fila, y convertir la fecha a _datetime_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscamos comparar a la par la cantidad promedio de ingresos a UCI con la cantidad promedio de casos confirmados **nuevos**. Para ello, necesitamos unir las dos tablas en base a la fecha. Traigamos esta información a nuestro _DataFrame_ con el que estábamos trabajando anteriormente (el que usamos para el último gráfico)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de eliminar todas las filas en que la media móvil está vacía en alguna de las dos columnas de medias móviles, calcule un nuevo indicador: la **tasa de hospitalización a UCI**, que indica cuál es el porcentaje de personas confirmadas que se hospitaliza en UCI. Para ello, tomaremos un supuesto fuerte que dice que los confirmados que se hospitalizan lo hacen inmediatamente después de confirmados (y no días después, como es la realidad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La campaña de vacunación comenzó para la población adulta el día 3 de febrero del 2021, ya superando al 50% de la población con dos dosis el día **20 de mayo del 2021**. Promedie la tasa de hospitalización antes del 20 de mayo del 2021, y después de esa fecha. ¿Qué puede concluir?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UCI por edad\n",
    "\n",
    "Montemos el último archivo, de UCIs por rango etario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasó lo mismo que con el otro. Formateemos acorde (repetir pasos sobre el otro dataframe de UCI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haga un gráfico de línea de la tabla anterior y maravíllese con la inteligencia de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a332da503d34353b4a88734c9c417394c5073dd13f9e5d25ac34ee4ac9b6e5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
